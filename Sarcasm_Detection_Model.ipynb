{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valia-p/Sarcasm_Detection/blob/main/Sarcasm_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The following model detects sarcasm, based on text and emojis."
      ],
      "metadata": {
        "id": "6ZmNx-ZmcLqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1: Setup & Imports"
      ],
      "metadata": {
        "id": "5uaYW8QnGN4N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5DgcwloofAH"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# STEP 1 — Setup & Imports\n",
        "# ==========================================\n",
        "!pip -q install emoji pandas scikit-learn matplotlib seaborn transformers accelerate pillow torchvision nlpaug\n",
        "\n",
        "import os, re, random, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import emoji as emoji_lib\n",
        "from collections import Counter\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, CLIPVisionModel, get_linear_schedule_with_warmup\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision import transforms\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# Reproducibility function: ensures consistent results across runs\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin = torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2: Download Dataset (isSarcasmEval)"
      ],
      "metadata": {
        "id": "vwV4rYZNGX1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 2 — Download Dataset (iSarcasmEval)\n",
        "# ==========================================\n",
        "!rm -rf iSarcasmEval\n",
        "!git clone -q https://github.com/iabufarha/iSarcasmEval.git\n",
        "print(\"Dataset downloaded.\")\n"
      ],
      "metadata": {
        "id": "arbsEEgm4Wq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3: Load Data & Train/Validation Split (No leakage)"
      ],
      "metadata": {
        "id": "v4Gn2EEeGmIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 3 — Load Data & Train/Val Split (No leakage)\n",
        "# ==========================================\n",
        "df_train = pd.read_csv(\"iSarcasmEval/train/train.En.csv\")[[\"tweet\", \"sarcastic\"]].rename(\n",
        "    columns={\"tweet\":\"text\", \"sarcastic\":\"label\"} # Keep only the tweet text and sarcasm label\n",
        ")\n",
        "df_test = pd.read_csv(\"iSarcasmEval/test/task_A_En_test.csv\")[[\"text\", \"sarcastic\"]].rename(\n",
        "    columns={\"text\":\"text\", \"sarcastic\":\"label\"} # We need the label for evaluations\n",
        ")\n",
        "\n",
        "# Clean empty rows\n",
        "df_train = df_train.dropna(subset=[\"text\"])\n",
        "df_train = df_train[df_train[\"text\"].str.strip() != \"\"].reset_index(drop=True)\n",
        "\n",
        "df_test = df_test.dropna(subset=[\"text\"])\n",
        "df_test = df_test[df_test[\"text\"].str.strip() != \"\"].reset_index(drop=True)\n",
        "\n",
        "# Split the training set into train (80%) and validation (20%) subsets\n",
        "train_df, val_df = train_test_split(\n",
        "    df_train, test_size=0.2, random_state=42, stratify=df_train[\"label\"]\n",
        ")\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df   = val_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Loaded: Train={len(df_train)} | Test={len(df_test)}\")\n",
        "print(f\"Split : Train={len(train_df)} | Val={len(val_df)} | Test={len(df_test)}\")\n",
        "print(\"Train label distribution:\", train_df[\"label\"].value_counts().to_dict())\n"
      ],
      "metadata": {
        "id": "AVnwAQp94aN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4: Quick Data Analysis (Train-focused)"
      ],
      "metadata": {
        "id": "pG12QJJ4Gwgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 4 — Quick Data Analysis (Train-focused)\n",
        "# ==========================================\n",
        "\n",
        "# Extracts all emojis from the text\n",
        "def extract_emojis(text):\n",
        "    return [c for c in str(text) if c in emoji_lib.EMOJI_DATA]\n",
        "\n",
        "\n",
        "# Computes how many texts contain at least one emoji\n",
        "# Returns the sum of the textx and the mean percentage\n",
        "def emoji_coverage(df):\n",
        "    has = df[\"text\"].apply(lambda t: any(c in emoji_lib.EMOJI_DATA for c in str(t)))\n",
        "    return int(has.sum()), float(has.mean()*100)\n",
        "\n",
        "train_eda = train_df.copy()\n",
        "\n",
        "# Compute word count per tweet\n",
        "train_eda[\"word_count\"] = train_eda[\"text\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Extract emojis per tweet\n",
        "train_eda[\"emojis_list\"] = train_eda[\"text\"].apply(extract_emojis)\n",
        "\n",
        "counts = train_eda[\"label\"].value_counts()\n",
        "sar = int(counts.get(1,0))\n",
        "nonsar = int(counts.get(0,0))\n",
        "# Compute class distribution\n",
        "sar_perc = sar/len(train_eda)*100\n",
        "\n",
        "tr_n, tr_p = emoji_coverage(train_df)\n",
        "va_n, va_p = emoji_coverage(val_df)\n",
        "te_n, te_p = emoji_coverage(df_test)\n",
        "\n",
        "# Most frequent emojis in training set\n",
        "top_10 = Counter([e for sub in train_eda[\"emojis_list\"] for e in sub]).most_common(10)\n",
        "\n",
        "print(\"--- DATA ANALYSIS SUMMARY (TRAIN) ---\")\n",
        "print(f\"Train={len(train_df)} | Val={len(val_df)} | Test={len(df_test)}\")\n",
        "print(f\"Class balance (TRAIN): NonSar={nonsar}, Sar={sar} ({sar_perc:.2f}%)\")\n",
        "if sar_perc < 30:\n",
        "    print(\"NOTE: Imbalance -> report F1 for sarcastic class (label=1).\")\n",
        "\n",
        "print(f\"Emoji coverage: Train={tr_n} ({tr_p:.2f}%) | Val={va_n} ({va_p:.2f}%) | Test={te_n} ({te_p:.2f}%)\")\n",
        "if top_10:\n",
        "    print(\"Top 5 Emojis (TRAIN):\", \", \".join([x[0] for x in top_10[:5]]))\n",
        "\n",
        "print(f\"Avg words (TRAIN): {train_eda['word_count'].mean():.1f} | Max words: {train_eda['word_count'].max()}\")\n",
        "\n",
        "PALETTE = [\"#6B7D2A\", \"#B7B08A\", \"#DCD6C6\", \"#3E4E1E\"]\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\", palette=PALETTE)\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "olive_beige_cmap = LinearSegmentedColormap.from_list(\n",
        "    \"olive_beige\",\n",
        "    [\"#DCD6C6\", \"#B7B08A\", \"#6B7D2A\", \"#3E4E1E\"]\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "# Plot 1: Class Distribution\n",
        "sns.countplot(\n",
        "    x=\"label\",\n",
        "    data=train_eda,\n",
        "    ax=axes[0],\n",
        "    palette=[\"#3E4E1E\", \"#B7B08A\"]  # olive / beige\n",
        ")\n",
        "axes[0].set_title(\"Train Class Distribution\")\n",
        "axes[0].set_xlabel(\"Label (0=Non-sarcastic, 1=Sarcastic)\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "\n",
        "# Plot 2: Text Length Distribution\n",
        "sns.histplot(\n",
        "    data=train_eda,\n",
        "    x=\"word_count\",\n",
        "    hue=\"label\",\n",
        "    kde=True,\n",
        "    bins=30,\n",
        "    ax=axes[1],\n",
        "    palette=[\"#3E4E1E\", \"#6B7D2A\"]\n",
        ")\n",
        "axes[1].set_title(\"Train Text Length Distribution\")\n",
        "axes[1].set_xlabel(\"Words\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "\n",
        "leg = axes[1].get_legend()\n",
        "if leg is not None:\n",
        "    leg.set_title(\"Label\")\n",
        "    leg.texts[0].set_text(\"Non-sarcastic\")\n",
        "    leg.texts[1].set_text(\"Sarcastic\")\n",
        "\n",
        "\n",
        "# Plot 3: Top 10 Emojis\n",
        "if top_10:\n",
        "    sns.barplot(\n",
        "        x=[e[0] for e in top_10],\n",
        "        y=[e[1] for e in top_10],\n",
        "        ax=axes[2],\n",
        "        color=\"#6B7D2A\"\n",
        "    )\n",
        "    axes[2].set_title(\"Top 10 Emojis (TRAIN)\")\n",
        "    axes[2].set_xlabel(\"Emoji\")\n",
        "    axes[2].set_ylabel(\"Count\")\n",
        "else:\n",
        "    axes[2].text(0.5, 0.5, \"No Emojis Found\", ha=\"center\", va=\"center\")\n",
        "\n",
        "\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "aLM5fdZk4cNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5: Algorithm 1 (Adapted Preprocess) <br>\n",
        "The following script provides preprocessed sets of training, validation and test data."
      ],
      "metadata": {
        "id": "AnfRApbKG7Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 5 — Algorithm 1 (Adapted Preprocess)\n",
        "# Outputs: train_proc, val_proc, test_proc\n",
        "# ==========================================\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "slang_dict = {\n",
        "    \"u\": \"you\", \"r\": \"are\", \"ur\": \"your\",\n",
        "    \"omg\": \"oh my god\", \"lol\": \"laugh out loud\",\n",
        "    \"idk\": \"i do not know\", \"brb\": \"be right back\",\n",
        "    \"gonna\": \"going to\", \"wanna\": \"want to\",\n",
        "    \"im\": \"i am\", \"tbh\": \"to be honest\"\n",
        "}\n",
        "\n",
        "# Performs cleaning without removing semantics\n",
        "def minimal_preprocess(text):\n",
        "    t = str(text).replace(\"\\n\",\" \").strip()\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \"\", t) # remove URLs\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip() # normalize spaces\n",
        "    return t\n",
        "\n",
        "# Replaces slang words based on the slang_dict\n",
        "def handle_slangs(text):\n",
        "    return \" \".join([slang_dict.get(w.lower(), w) for w in str(text).split()])\n",
        "\n",
        "# Keeps raw text explicitly for emoji-to-image processing\n",
        "def base_pipeline(df):\n",
        "    out = df.dropna(subset=[\"text\"]).copy()\n",
        "    out = out[out[\"text\"].str.strip() != \"\"].reset_index(drop=True)\n",
        "\n",
        "    out[\"raw_text_for_emoji\"] = out[\"text\"]  # IMPORTANT: keep raw for emoji-image\n",
        "    out[\"final_text\"] = out[\"text\"].apply(minimal_preprocess).apply(handle_slangs)\n",
        "    return out[[\"final_text\",\"raw_text_for_emoji\",\"label\"]]\n",
        "\n",
        "# Augmentation ONLY on train\n",
        "AUG_PROB = 0.2\n",
        "aug = naw.SynonymAug(aug_src=\"wordnet\") # synonym replacement\n",
        "\n",
        "# Randomnly augments text with synonyms for robustness\n",
        "def augment_text(text):\n",
        "    if random.random() > AUG_PROB:\n",
        "        return text\n",
        "    try:\n",
        "        # We leave short text as is\n",
        "        if len(text.split()) > 5:\n",
        "            return aug.augment(text)[0]\n",
        "    except:\n",
        "        pass\n",
        "    return text\n",
        "\n",
        "train_proc = base_pipeline(train_df)\n",
        "train_proc[\"final_text\"] = train_proc[\"final_text\"].apply(augment_text)\n",
        "\n",
        "val_proc  = base_pipeline(val_df)\n",
        "test_proc = base_pipeline(df_test)\n",
        "\n",
        "print(f\"Algo1 done -> Train:{len(train_proc)} | Val:{len(val_proc)} | Test:{len(test_proc)}\")\n",
        "print(\"Sample RAW  :\", train_proc[\"raw_text_for_emoji\"].iloc[0])\n",
        "print(\"Sample FINAL:\", train_proc[\"final_text\"].iloc[0])\n"
      ],
      "metadata": {
        "id": "U_cjMf064ehS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 6: Tokenizer + Text Dataset + Loaders <br>\n",
        "The following script provides DataLoaders for training, validation and testing by using RoBERTa transformer as tokenizer."
      ],
      "metadata": {
        "id": "nNWkPFvAHsr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP 6 — Tokenizer + Text Dataset + Loaders\n",
        "# ============================================\n",
        "MODEL_NAME = \"roberta-base\" # Pre-trained transformer\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Handles text tokenization and samples for the model\n",
        "class SarcasmTextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=128):\n",
        "        self.texts = df[\"final_text\"].tolist()\n",
        "        self.raws  = df[\"raw_text_for_emoji\"].tolist()\n",
        "        self.labels = df[\"label\"].astype(int).tolist() # binary labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts) # num of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        raw  = str(self.raws[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # Returns dictionary compatible with HuggingFace / Pytorch models\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "            \"raw_text\": raw\n",
        "        }\n",
        "\n",
        "# We wrap the data in DataLoader for efficient training\n",
        "train_loader = DataLoader(SarcasmTextDataset(train_proc, tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(SarcasmTextDataset(val_proc,   tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(SarcasmTextDataset(test_proc,  tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Text loaders ready.\")\n"
      ],
      "metadata": {
        "id": "GE-6ZDTf4gx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 7: Baseline Model (Paper-inspired) <br>\n",
        "RoBERTa-based model that enriches contextual embeddings with stacked-attention blocks."
      ],
      "metadata": {
        "id": "wFDjqHQ2Iumm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 7 — Baseline Model (Paper-inspired)\n",
        "# RoBERTa + cascaded (MUltiHead Attention + DepthwiseConv) blocks\n",
        "# ==========================================\n",
        "\n",
        "# Combines self-attention for global content with deep convolution for local feature extraction\n",
        "class AttnConvBlock(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=8, dropout=0.2):\n",
        "        super().__init__()\n",
        "        # MultiHead Self-attention layer\n",
        "        self.mha = nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # Depthwise 1D convolution (tokenwise local content)\n",
        "        # groups=hidden_dim ensures depthwise operation\n",
        "        self.dwconv = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1, groups=hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        # attention_mask: 1 for token, 0 for padding\n",
        "        # Convert to key padding mask expected by PyTorch MHA\n",
        "        key_padding_mask = ~attention_mask.bool()  # True on PAD => ignore\n",
        "\n",
        "        # Self-attention with residual connections\n",
        "        attn_out, _ = self.mha(x, x, x, key_padding_mask=key_padding_mask)\n",
        "        x = self.norm1(x + self.drop(attn_out))\n",
        "\n",
        "        # Depthwise convolution with residual connection\n",
        "        y = self.dwconv(x.permute(0,2,1)).permute(0,2,1)\n",
        "        x = self.norm2(x + self.drop(y))\n",
        "        return x\n",
        "\n",
        "# Baseline Sarcasm Classifier\n",
        "# Transformer encoder with stacked attention - convo blocks\n",
        "class KhanBaselineModel(nn.Module):\n",
        "    def __init__(self, model_name=MODEL_NAME, num_labels=2, num_blocks=2, num_heads=8, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(model_name) # pre-trained RoBERTs encoder\n",
        "        self.hidden_dim = self.roberta.config.hidden_size  # IMPORTANT: used by variant\n",
        "\n",
        "        # Stack of attention - convolution blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            AttnConvBlock(self.hidden_dim, num_heads=num_heads, dropout=dropout)\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.hidden_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Extract contextualed token embeddings from RobERTa\n",
        "        x = self.roberta(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "\n",
        "        # Apply cascaded attention - convo blocks\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x, attention_mask)\n",
        "        cls = x[:, 0, :] # token representation for classifications\n",
        "        return self.classifier(self.drop(cls))\n",
        "\n",
        "print(\"Baseline model class ready.\")\n"
      ],
      "metadata": {
        "id": "WQqLTOt14im1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 8: Shared Utils (metrics + confusion matrix + eval)"
      ],
      "metadata": {
        "id": "COfBLnHRMDRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 8 — Shared Utils (metrics + confusion matrix + eval)\n",
        "# ==========================================\n",
        "\n",
        "# Focuses on the sarcastic class\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"acc\": accuracy_score(y_true, y_pred),\n",
        "        \"prec\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"rec\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "    }\n",
        "\n",
        "def plot_cm(y_true, y_pred, title, cmap=\"Blues\"):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.xticks([0.5, 1.5], [\"Non-Sarcastic\",\"Sarcastic\"])\n",
        "    plt.yticks([0.5, 1.5], [\"Non-Sarcastic\",\"Sarcastic\"], rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Model Evaluation: evaluated text-based model on a given DataLoader\n",
        "def eval_text_model(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    losses, preds, labels_all, raws = [], [], [], []\n",
        "\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            # Move batch to device\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(ids, mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Predicted class labels\n",
        "            p = torch.argmax(logits, dim=1).cpu().numpy().tolist()\n",
        "            preds.extend(p)\n",
        "            labels_all.extend(labels.cpu().numpy().tolist())\n",
        "\n",
        "            raws.extend(batch[\"raw_text\"])\n",
        "\n",
        "    metrics = compute_metrics(labels_all, preds)\n",
        "    metrics[\"loss\"] = float(np.mean(losses))\n",
        "    return metrics, np.array(labels_all), np.array(preds), np.array(raws)\n"
      ],
      "metadata": {
        "id": "gJNc3vfA4kZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 9: Weighted Loss (handles imbalance) <br>\n",
        "The following script addresses class imbalance with the help of an inverse-frequency weighted cross-entropy loss --> ensures that errors contribute more strongly during training."
      ],
      "metadata": {
        "id": "TmRNc_NPN6Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 9 — Weighted Loss (handles imbalance)\n",
        "# ==========================================\n",
        "\n",
        "# Number of samples per class in the training set\n",
        "cnt = Counter(train_proc[\"label\"].tolist())\n",
        "# This penalizes misclassification of rare samples more strongly\n",
        "w0 = 1.0 / cnt[0]\n",
        "w1 = 1.0 / cnt[1]\n",
        "# Create weight tensor for CrossEntropyLoss\n",
        "class_weights = torch.tensor([w0, w1], dtype=torch.float).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "print(\"Weighted loss enabled.\")\n",
        "print(\"Class counts:\", dict(cnt))\n",
        "print(\"Class weights:\", class_weights.detach().cpu().numpy().tolist())\n"
      ],
      "metadata": {
        "id": "UiMk8zAK4oa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 10: Train Baseline (validate on Val, test once)<br>\n",
        "The following script trains the basline sarcasm model using weighted loss, selects the best checkpoint based on f1 score and performs a single evaluation (not biased) on the test set."
      ],
      "metadata": {
        "id": "J21HvN2_QIHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 10 — Train Baseline (validate on Val, test once)\n",
        "# ==========================================\n",
        "baseline_model = KhanBaselineModel(num_blocks=2, dropout=0.2).to(device)\n",
        "\n",
        "optimizer = AdamW(baseline_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "epochs = 4\n",
        "total_steps = len(train_loader) * epochs\n",
        "# Linear learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Tracking best model\n",
        "best_val_f1 = -1.0\n",
        "best_state = None\n",
        "hist_train_loss, hist_val_f1 = [], []\n",
        "\n",
        "print(\"Training Baseline...\")\n",
        "\n",
        "# Training loop\n",
        "for ep in range(1, epochs+1):\n",
        "    t0 = time.time()\n",
        "    baseline_model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move batch to device\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = baseline_model(ids, mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping for training stability\n",
        "        torch.nn.utils.clip_grad_norm_(baseline_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_loss = running_loss / max(1, len(train_loader))\n",
        "    val_metrics, _, _, _ = eval_text_model(baseline_model, val_loader, loss_fn)\n",
        "\n",
        "    hist_train_loss.append(train_loss)\n",
        "    hist_val_f1.append(val_metrics[\"f1\"])\n",
        "\n",
        "    print(f\"Epoch {ep}/{epochs} | train_loss={train_loss:.4f} | val_f1={val_metrics['f1']:.4f} | \"\n",
        "          f\"val_acc={val_metrics['acc']:.4f} | time={time.time()-t0:.1f}s\")\n",
        "\n",
        "    # Saves best-performing model based on f1\n",
        "    if val_metrics[\"f1\"] > best_val_f1:\n",
        "        best_val_f1 = val_metrics[\"f1\"]\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in baseline_model.state_dict().items()}\n",
        "\n",
        "# restore best\n",
        "if best_state is not None:\n",
        "    baseline_model.load_state_dict(best_state)\n",
        "\n",
        "print(f\"\\nBest VAL F1 (baseline): {best_val_f1:.4f}\")\n",
        "\n",
        "# Final evaluation on test set (evaluated once to avoid optimistic bias)\n",
        "baseline_test_metrics, y_true_b, y_pred_b, raw_b = eval_text_model(baseline_model, test_loader, loss_fn)\n",
        "print(\"\\nBASELINE — FINAL TEST METRICS:\", baseline_test_metrics)\n",
        "plot_cm(\n",
        "    y_true_b,\n",
        "    y_pred_b,\n",
        "    f\"Baseline (Test) | F1={baseline_test_metrics['f1']:.3f}\",\n",
        "    cmap=olive_beige_cmap\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist_train_loss, label=\"train_loss\", color=\"#6B7D2A\")\n",
        "plt.title(\"Baseline Training Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist_val_f1, label=\"val_f1\", color=\"#B7B08A\")\n",
        "plt.title(\"Baseline Validation F1\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"F1\"); plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "akieuWRa4qFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 11: Multimodal Data (Emoji-image + emoji_count)<br>\n",
        "The following script creates a multimodal dataset by augmenting textual inputs with visual emoji representations and a scalar emoji-count feature."
      ],
      "metadata": {
        "id": "PiPVFcgxSA6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 11 — Multimodal Data (Emoji-image + emoji_count)\n",
        "# ==========================================\n",
        "# Emoji font for rendering\n",
        "FONT_PATH = \"NotoColorEmoji.ttf\"\n",
        "if not os.path.exists(FONT_PATH):\n",
        "    !wget -q -O NotoColorEmoji.ttf https://github.com/googlefonts/noto-emoji/raw/main/fonts/NotoColorEmoji.ttf\n",
        "\n",
        "IMG_SIZE = 224\n",
        "try:\n",
        "    emoji_font = ImageFont.truetype(FONT_PATH, 90)\n",
        "    print(\"Emoji font loaded.\")\n",
        "except:\n",
        "    emoji_font = None\n",
        "    print(\"Emoji font not loaded. Emojis may render poorly on some envs.\")\n",
        "\n",
        "# Clip-stylle image preprocessing\n",
        "clip_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.481, 0.457, 0.408], std=[0.268, 0.261, 0.275])\n",
        "])\n",
        "\n",
        "# Extracts emoji characters from text\n",
        "def extract_emojis(text):\n",
        "    return [c for c in str(text) if c in emoji_lib.EMOJI_DATA]\n",
        "\n",
        "def emoji_count(text):\n",
        "    return sum(1 for c in str(text) if c in emoji_lib.EMOJI_DATA)\n",
        "\n",
        "# Renders up to 4 emojis into a 2x2 image grid\n",
        "# If no emojis exist, a placeholder image is created\n",
        "def render_emoji_grid(raw_text):\n",
        "    \"\"\"\n",
        "    Up to 4 emojis in a 2x2 grid.\n",
        "    If none -> NO_EMOJI image.\n",
        "    \"\"\"\n",
        "    ems = extract_emojis(raw_text)\n",
        "    img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), (0,0,0))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    if len(ems) == 0:\n",
        "        draw.text((35, 90), \"NO\\nEMOJI\", fill=(255,255,255))\n",
        "        return clip_transform(img)\n",
        "\n",
        "    # Limit to first 4 emojis\n",
        "    ems = ems[:4]\n",
        "    positions = [(30,25),(120,25),(30,125),(120,125)]\n",
        "    for e,(x,y) in zip(ems, positions): # Draw emojis on the grid\n",
        "        try:\n",
        "            if emoji_font is not None:\n",
        "                draw.text((x,y), e, font=emoji_font, embedded_color=True)\n",
        "            else:\n",
        "                draw.text((x,y), e, fill=(255,255,255))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return clip_transform(img)\n",
        "\n",
        "class SarcasmMultimodalDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=128):\n",
        "        self.texts = df[\"final_text\"].tolist()\n",
        "        self.raws  = df[\"raw_text_for_emoji\"].tolist()\n",
        "        self.labels = df[\"label\"].astype(int).tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        raw  = str(self.raws[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"pixel_values\": render_emoji_grid(raw),\n",
        "            # Scalar emoji count feature\n",
        "            \"emoji_count\": torch.tensor([emoji_count(raw)], dtype=torch.float),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "            \"raw_text\": raw\n",
        "        }\n",
        "\n",
        "train_loader_mm = DataLoader(SarcasmMultimodalDataset(train_proc, tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=True,  pin_memory=pin)\n",
        "val_loader_mm   = DataLoader(SarcasmMultimodalDataset(val_proc,   tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=False, pin_memory=pin)\n",
        "test_loader_mm  = DataLoader(SarcasmMultimodalDataset(test_proc,  tokenizer, MAX_LEN), batch_size=BATCH_SIZE, shuffle=False, pin_memory=pin)\n",
        "\n",
        "print(\"Multimodal loaders ready.\")\n"
      ],
      "metadata": {
        "id": "SBN1t7tv4tEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 12: Multimodal Variant Model\n",
        "- text backbone = baseline architecture\n",
        "- loads baseline trained weights (crucial!)\n",
        "- CLIP vision + emoji_count scalar\n",
        "\n",
        "The following script defines a multimodal sarcasm detection model that fuses pretrained textual features, visual emoji representations, and emoji frequency, leveraging transfer learning by initializing the text branch with a fully trained baseline and applying lightweight fine-tuning to the vision encoder."
      ],
      "metadata": {
        "id": "wNolmxg3UDt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 12 — Multimodal Variant Model\n",
        "# - text backbone = baseline architecture\n",
        "# - loads baseline trained weights (crucial!)\n",
        "# - CLIP vision + emoji_count scalar\n",
        "# ==========================================\n",
        "\n",
        "# Multimodal sarcasm classifier that combines:\n",
        "# -> Textual features from the baseline RoBERTa-based model\n",
        "# -> Visual emoji features from CLIP\n",
        "# -> Scalar emoji count\n",
        "class MultimodalSarcasmModel(nn.Module):\n",
        "    def __init__(self, model_name=MODEL_NAME, dropout=0.2, num_labels=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Text branch: same as baseline (paper-inspired)\n",
        "        self.text_model = KhanBaselineModel(model_name=model_name, num_labels=num_labels, num_blocks=2, num_heads=8, dropout=dropout)\n",
        "        hidden_dim = self.text_model.hidden_dim\n",
        "\n",
        "        # Make it a feature extractor\n",
        "        self.text_model.classifier = nn.Identity()  # returns (B, hidden_dim)\n",
        "\n",
        "        # Vision branch: CLIP\n",
        "        # Pretrained CLIP vision encoder for emoji-image features\n",
        "        self.img_enc = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        vision_dim = self.img_enc.config.hidden_size\n",
        "\n",
        "        # Fusion: [text_feat, img_feat, emoji_count(1)]\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + vision_dim + 1, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, pixel_values, emoji_count):\n",
        "        # Extract textual features\n",
        "        txt_feat = self.text_model(input_ids, attention_mask)  # (B, hidden_dim)\n",
        "        # Extract visual emoji features\n",
        "        img_feat = self.img_enc(pixel_values=pixel_values).pooler_output  # (B, vision_dim)\n",
        "        # Feature fusion\n",
        "        fused = torch.cat([txt_feat, img_feat, emoji_count], dim=1)\n",
        "        return self.classifier(fused)\n",
        "\n",
        "variant_model = MultimodalSarcasmModel(dropout=0.2).to(device)\n",
        "\n",
        "# KEY STEP: load trained baseline weights into variant text branch\n",
        "variant_model.text_model.load_state_dict(baseline_model.state_dict(), strict=False)\n",
        "print(\"Loaded baseline weights into variant text branch.\")\n",
        "\n",
        "# Freeze all CLIP first\n",
        "for p in variant_model.img_enc.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# Unfreeze ONLY last CLIP encoder layer (light fine-tuning)\n",
        "for p in variant_model.img_enc.vision_model.encoder.layers[-1].parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "print(\"CLIP frozen except last encoder layer.\")\n"
      ],
      "metadata": {
        "id": "6t3AfkSq4txB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 13: Train Variant (validate on Val, test once, rich logging) <br>\n",
        "The following script trains the multimodal sarcasm detection model using weighted loss and controlled fine-tuning, selects the best checkpoint based on validation F1-score, and evaluates the final model once on the test set,"
      ],
      "metadata": {
        "id": "ipPmJBvaVdfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 13 — Train Variant (validate on Val, test once, rich logging)\n",
        "# ==========================================\n",
        "\n",
        "# Similar to eval_text_model, but adapted for multimodal inputs\n",
        "def eval_mm_model(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    losses, preds, labels_all, raws = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            pix = batch[\"pixel_values\"].to(device)\n",
        "            ec  = batch[\"emoji_count\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(ids, mask, pix, ec)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Predictions\n",
        "            p = torch.argmax(logits, dim=1).cpu().numpy().tolist()\n",
        "            preds.extend(p)\n",
        "            labels_all.extend(labels.cpu().numpy().tolist())\n",
        "            raws.extend(batch[\"raw_text\"])\n",
        "\n",
        "    metrics = compute_metrics(labels_all, preds)\n",
        "    metrics[\"loss\"] = float(np.mean(losses)) if len(losses) else 0.0\n",
        "    return metrics, np.array(labels_all), np.array(preds), np.array(raws)\n",
        "\n",
        "# -----------------------------\n",
        "# Optimizer/Scheduler\n",
        "# -----------------------------\n",
        "optimizer = AdamW(\n",
        "    filter(lambda p: p.requires_grad, variant_model.parameters()),\n",
        "    lr=2e-5,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_loader_mm) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "best_val_f1 = -1.0\n",
        "best_state = None\n",
        "best_epoch = -1\n",
        "\n",
        "hist = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_f1\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_f1\": [],\n",
        "    \"val_acc\": []\n",
        "}\n",
        "\n",
        "print(\"Training Variant (Multimodal)...\")\n",
        "\n",
        "# Training Loop\n",
        "for ep in range(1, epochs + 1):\n",
        "    t0 = time.time()\n",
        "    variant_model.train()\n",
        "\n",
        "    train_losses = []\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    for batch in train_loader_mm:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        pix = batch[\"pixel_values\"].to(device)\n",
        "        ec  = batch[\"emoji_count\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward   + Loss\n",
        "        logits = variant_model(ids, mask, pix, ec)\n",
        "        loss = loss_fn(logits, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(variant_model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_preds.extend(torch.argmax(logits, dim=1).detach().cpu().numpy().tolist())\n",
        "        train_labels.extend(labels.detach().cpu().numpy().tolist())\n",
        "\n",
        "    # Train metrics (for presentation)\n",
        "    train_loss = float(np.mean(train_losses)) if len(train_losses) else 0.0\n",
        "    train_f1 = f1_score(train_labels, train_preds, pos_label=1, zero_division=0)\n",
        "\n",
        "    # Val metrics\n",
        "    val_metrics, _, _, _ = eval_mm_model(variant_model, val_loader_mm, loss_fn)\n",
        "\n",
        "    hist[\"train_loss\"].append(train_loss)\n",
        "    hist[\"train_f1\"].append(train_f1)\n",
        "    hist[\"val_loss\"].append(val_metrics[\"loss\"])\n",
        "    hist[\"val_f1\"].append(val_metrics[\"f1\"])\n",
        "    hist[\"val_acc\"].append(val_metrics[\"acc\"])\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {ep}/{epochs} | \"\n",
        "        f\"train_loss={train_loss:.4f} train_f1={train_f1:.4f} | \"\n",
        "        f\"val_loss={val_metrics['loss']:.4f} val_f1={val_metrics['f1']:.4f} val_acc={val_metrics['acc']:.4f} | \"\n",
        "        f\"time={time.time()-t0:.1f}s\"\n",
        "    )\n",
        "\n",
        "    # Save best by Val F1\n",
        "    if val_metrics[\"f1\"] > best_val_f1:\n",
        "        best_val_f1 = val_metrics[\"f1\"]\n",
        "        best_epoch = ep\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in variant_model.state_dict().items()}\n",
        "\n",
        "# Restore best\n",
        "if best_state is not None:\n",
        "    variant_model.load_state_dict(best_state)\n",
        "\n",
        "print(f\"\\nBest VAL F1 (variant): {best_val_f1:.4f} (epoch {best_epoch})\")\n",
        "\n",
        "# -----------------------------\n",
        "# Final Test (once)\n",
        "# -----------------------------\n",
        "variant_test_metrics, y_true_v, y_pred_v, raw_v = eval_mm_model(variant_model, test_loader_mm, loss_fn)\n",
        "\n",
        "print(\"\\n\" + \"=\"*55)\n",
        "print(\"VARIANT — FINAL TEST METRICS\")\n",
        "print(\"=\"*55)\n",
        "print(variant_test_metrics)\n",
        "\n",
        "plot_cm(y_true_v, y_pred_v, f\"Variant (Test) | F1={variant_test_metrics['f1']:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Curves (presentation friendly)\n",
        "# -----------------------------\n",
        "plt.figure()\n",
        "plt.plot(hist[\"train_loss\"], label=\"train_loss\")\n",
        "plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Variant Loss Curves\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist[\"train_f1\"], label=\"train_f1\")\n",
        "plt.plot(hist[\"val_f1\"], label=\"val_f1\")\n",
        "plt.title(\"Variant F1 Curves (Sarcastic class)\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"F1\"); plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yMEk4ssg8y1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 14: Final Comparison + Side-by-side Confusion Matrices (Rich) <br>\n",
        "The following script provides a final comparison between the text-only baseline and the multimodal variant on the test set."
      ],
      "metadata": {
        "id": "3XHGVRUFXLXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 14 — Final Comparison + Side-by-side Confusion Matrices (Rich)\n",
        "# ==========================================\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    f1_score, precision_score, recall_score, accuracy_score\n",
        ")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Computes a rich set of metrics for binary classification\n",
        "def pretty_metrics(name, y_true, y_pred, loss=None):\n",
        "    out = {\n",
        "        \"acc\": accuracy_score(y_true, y_pred),\n",
        "        \"prec(1)\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"rec(1)\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"f1(1)\": f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
        "    }\n",
        "    if loss is not None:\n",
        "        out[\"loss\"] = loss\n",
        "    return name, out\n",
        "\n",
        "print(\"\\n\" + \"=\"*65)\n",
        "print(\"FINAL RESULTS (TEST) — Baseline vs Variant\")\n",
        "print(\"=\"*65)\n",
        "\n",
        "# Same test ordering & labels (both models were evaluated on the same test sample)\n",
        "assert len(y_true_b) == len(y_true_v), \"Mismatch: test sizes differ!\"\n",
        "assert np.all(np.array(y_true_b) == np.array(y_true_v)), \"Mismatch: label order differs!\"\n",
        "\n",
        "# Metrics tables\n",
        "base_name, base_out = pretty_metrics(\"Baseline\", y_true_b, y_pred_b, loss=baseline_test_metrics.get(\"loss\"))\n",
        "var_name,  var_out  = pretty_metrics(\"Variant\",  y_true_v, y_pred_v,  loss=variant_test_metrics.get(\"loss\"))\n",
        "\n",
        "print(f\"{base_name}: {base_out}\")\n",
        "print(f\"{var_name} : {var_out}\")\n",
        "\n",
        "diff_f1 = var_out[\"f1(1)\"] - base_out[\"f1(1)\"]\n",
        "diff_acc = var_out[\"acc\"] - base_out[\"acc\"]\n",
        "print(\"-\"*65)\n",
        "print(f\"ΔF1(1)  (Variant - Baseline) = {diff_f1:+.4f}\")\n",
        "print(f\"ΔAcc   (Variant - Baseline) = {diff_acc:+.4f}\")\n",
        "\n",
        "# Confusion matrices\n",
        "cm_base = confusion_matrix(y_true_b, y_pred_b)\n",
        "cm_var  = confusion_matrix(y_true_v, y_pred_v)\n",
        "\n",
        "# TN, FP, FN, TP (binary)\n",
        "tn_b, fp_b, fn_b, tp_b = cm_base.ravel()\n",
        "tn_v, fp_v, fn_v, tp_v = cm_var.ravel()\n",
        "\n",
        "print(\"\\n\" + \"=\"*65)\n",
        "print(\"Confusion Matrix Breakdown (TEST)\")\n",
        "print(\"=\"*65)\n",
        "print(f\"Baseline: TN={tn_b}, FP={fp_b}, FN={fn_b}, TP={tp_b}\")\n",
        "print(f\"Variant : TN={tn_v}, FP={fp_v}, FN={fn_v}, TP={tp_v}\")\n",
        "\n",
        "# Optional: short classification reports (useful in slides)\n",
        "print(\"\\n\" + \"=\"*65)\n",
        "print(\"Classification Report (TEST) — Baseline\")\n",
        "print(\"=\"*65)\n",
        "print(classification_report(y_true_b, y_pred_b, digits=4, zero_division=0))\n",
        "\n",
        "print(\"\\n\" + \"=\"*65)\n",
        "print(\"Classification Report (TEST) — Variant\")\n",
        "print(\"=\"*65)\n",
        "print(classification_report(y_true_v, y_pred_v, digits=4, zero_division=0))\n",
        "\n",
        "# Baseline heatmap\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(cm_base, annot=True, fmt=\"d\", cmap=olive_beige_cmap)\n",
        "plt.title(f\"Baseline (Text)\\nF1(1)={base_out['f1(1)']:.3f} | Acc={base_out['acc']:.3f}\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.xticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"])\n",
        "plt.yticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"], rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Variant heatmap\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(cm_var, annot=True, fmt=\"d\",cmap=olive_beige_cmap)\n",
        "plt.title(f\"Variant (Multimodal)\\nF1(1)={var_out['f1(1)']:.3f} | Acc={var_out['acc']:.3f}\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.xticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"])\n",
        "plt.yticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"], rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZeP1Yb8V80yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 15: Golden / Reverse Golden + Emoji-only + No-emoji splits (Rich) <br>\n",
        "Requires:\n",
        "- y_true_b, y_pred_b from baseline test\n",
        "- y_true_v, y_pred_v from variant test\n",
        "- raw_v (texts from multimodal test loader, raw text)\n",
        "\n",
        "The following script performs a detailed error analysis focusing on sarcastic tweets, identifying “golden” cases where the multimodal model correctly predicts sarcasm missed by the text-only baseline, and “reverse golden” cases where multimodality leads to errors. By further splitting these cases into emoji-containing and emoji-free subsets, we demonstrate that the majority of multimodal improvements are strongly correlated with emoji usage, providing concrete evidence that emoji-based visual and count features contribute meaningfully to sarcasm detection."
      ],
      "metadata": {
        "id": "J5EMENozX_-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 15 — Golden / Reverse Golden + Emoji-only + No-emoji splits (Rich)\n",
        "# Requires:\n",
        "# - y_true_b, y_pred_b from baseline test\n",
        "# - y_true_v, y_pred_v from variant test\n",
        "# - raw_v (texts from multimodal test loader, raw text)\n",
        "# ==========================================\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def has_emoji(text):\n",
        "    return any(c in emoji_lib.EMOJI_DATA for c in str(text))\n",
        "\n",
        "# Extracts actual emoji symbols\n",
        "def extract_emojis(text):\n",
        "    return [c for c in str(text) if c in emoji_lib.EMOJI_DATA]\n",
        "\n",
        "# --- Alignment safety ---\n",
        "y_b = np.array(y_true_b)\n",
        "y_v = np.array(y_true_v)\n",
        "b = np.array(y_pred_b)\n",
        "v = np.array(y_pred_v)\n",
        "texts = np.array(raw_v, dtype=object)\n",
        "\n",
        "assert len(y_b) == len(y_v) == len(texts), \"Mismatch in test lengths!\"\n",
        "assert np.all(y_b == y_v), \"Label order differs between baseline & variant test loaders!\"\n",
        "\n",
        "y = y_b  # same as y_v now\n",
        "\n",
        "# --- Indices ---\n",
        "gold = np.where((y == 1) & (b == 0) & (v == 1))[0]   # Variant catches sarcasm baseline misses\n",
        "rev  = np.where((y == 1) & (b == 1) & (v == 0))[0]   # Baseline catches sarcasm variant misses\n",
        "\n",
        "# --- Split by emoji presence ---\n",
        "gold_emoji = [idx for idx in gold if has_emoji(texts[idx])]\n",
        "gold_no    = [idx for idx in gold if not has_emoji(texts[idx])]\n",
        "rev_emoji  = [idx for idx in rev  if has_emoji(texts[idx])]\n",
        "rev_no     = [idx for idx in rev  if not has_emoji(texts[idx])]\n",
        "\n",
        "# --- Summary ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GOLDEN / REVERSE GOLDEN SUMMARY (TEST)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Golden (True=1, Baseline=0, Variant=1): {len(gold)}\")\n",
        "print(f\"  ├─ with emoji: {len(gold_emoji)}\")\n",
        "print(f\"  └─ no emoji  : {len(gold_no)}\")\n",
        "print(f\"Reverse (True=1, Baseline=1, Variant=0): {len(rev)}\")\n",
        "print(f\"  ├─ with emoji: {len(rev_emoji)}\")\n",
        "print(f\"  └─ no emoji  : {len(rev_no)}\")\n",
        "\n",
        "# --- Helper printer ---\n",
        "def print_examples(title, idx_list, limit=5):\n",
        "    print(\"\\n\" + title)\n",
        "    print(\"-\"*70)\n",
        "    if len(idx_list) == 0:\n",
        "        print(\"(none in this run)\")\n",
        "        return\n",
        "\n",
        "    for i, idx in enumerate(idx_list[:limit], start=1):\n",
        "        ems = extract_emojis(texts[idx])\n",
        "        ems_str = \" \".join(ems) if ems else \"(no emoji)\"\n",
        "        print(f\"[{i}] {texts[idx]}\")\n",
        "        print(f\"    Emojis: {ems_str}\")\n",
        "        print(f\"    True=1 | Baseline={b[idx]} | Variant={v[idx]}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "# --- Print examples ---\n",
        "print_examples(\"GOLDEN EXAMPLES (ALL)\", list(gold), limit=5)\n",
        "print_examples(\"REVERSE GOLDEN (ALL)\", list(rev), limit=5)\n",
        "\n",
        "print_examples(\"GOLDEN EXAMPLES (EMOJI-ONLY)\", gold_emoji, limit=5)\n",
        "print_examples(\"REVERSE GOLDEN (EMOJI-ONLY)\", rev_emoji, limit=5)\n",
        "\n",
        "print_examples(\"GOLDEN EXAMPLES (NO-EMOJI ONLY)\", gold_no, limit=5)\n",
        "print_examples(\"REVERSE GOLDEN (NO-EMOJI ONLY)\", rev_no, limit=5)\n",
        "\n",
        "# --- Optional: Top emojis inside golden/reverse emoji-only sets ---\n",
        "if len(gold_emoji) > 0:\n",
        "    gold_emoji_list = [e for idx in gold_emoji for e in extract_emojis(texts[idx])]\n",
        "    print(\"\\nTop emojis in GOLDEN (emoji-only):\", Counter(gold_emoji_list).most_common(10))\n",
        "\n",
        "if len(rev_emoji) > 0:\n",
        "    rev_emoji_list = [e for idx in rev_emoji for e in extract_emojis(texts[idx])]\n",
        "    print(\"Top emojis in REVERSE (emoji-only):\", Counter(rev_emoji_list).most_common(10))\n"
      ],
      "metadata": {
        "id": "MuhKDfWnCt4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 16 — Emoji-only Evaluation (Test subset)\n",
        "Compares Baseline vs Variant ONLY on tweets that contain emoji\n",
        "Requires:\n",
        "- y_true_b, y_pred_b from baseline test\n",
        "- y_true_v, y_pred_v from variant test\n",
        "- raw_v (raw texts from multimodal test loader, includes emojis)\n",
        "\n",
        "The following script isolates emoji-containing test tweets and demonstrates that the multimodal model achieves higher sarcasm detection performance precisely in the cases where emojis are present"
      ],
      "metadata": {
        "id": "PeWhMN09ZHCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 16 — Emoji-only Evaluation (Test subset)\n",
        "# Compares Baseline vs Variant ONLY on tweets that contain emoji\n",
        "# Requires:\n",
        "# - y_true_b, y_pred_b from baseline test\n",
        "# - y_true_v, y_pred_v from variant test\n",
        "# - raw_v (raw texts from multimodal test loader, includes emojis)\n",
        "# ==========================================\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# --- Safety alignment checks ---\n",
        "y_b = np.array(y_true_b)\n",
        "y_v = np.array(y_true_v)\n",
        "b = np.array(y_pred_b)\n",
        "v = np.array(y_pred_v)\n",
        "texts = np.array(raw_v, dtype=object)\n",
        "\n",
        "assert len(y_b) == len(y_v) == len(texts), \"Mismatch in test lengths!\"\n",
        "assert np.all(y_b == y_v), \"Label order differs between baseline & variant test loaders!\"\n",
        "\n",
        "y = y_b # Single ground truth reference\n",
        "\n",
        "def has_emoji(text):\n",
        "    return any(c in emoji_lib.EMOJI_DATA for c in str(text))\n",
        "\n",
        "# Computes task-relevant metrics\n",
        "def metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"acc\": accuracy_score(y_true, y_pred),\n",
        "        \"prec\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"rec\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "    }\n",
        "\n",
        "# --- Build emoji-only mask ---\n",
        "emoji_mask = np.array([has_emoji(t) for t in texts], dtype=bool)\n",
        "idxs = np.where(emoji_mask)[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EMOJI-ONLY EVALUATION (TEST SUBSET)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Emoji tweets in TEST: {len(idxs)} / {len(texts)} ({len(idxs)/len(texts)*100:.2f}%)\")\n",
        "\n",
        "if len(idxs) == 0:\n",
        "    print(\"No emoji tweets found in test set (unexpected).\")\n",
        "else:\n",
        "    y_e = y[idxs]\n",
        "    b_e = b[idxs]\n",
        "    v_e = v[idxs]\n",
        "\n",
        "    base_m = metrics(y_e, b_e)\n",
        "    var_m  = metrics(y_e, v_e)\n",
        "\n",
        "    print(\"\\nBaseline (emoji-only):\", base_m)\n",
        "    print(\"Variant  (emoji-only):\", var_m)\n",
        "\n",
        "    # Direct improvement in sarcastic f1\n",
        "    diff = var_m[\"f1\"] - base_m[\"f1\"]\n",
        "    print(\"-\"*70)\n",
        "    print(f\"ΔF1 (Variant - Baseline) on emoji-only = {diff:+.4f}\")\n",
        "\n",
        "    # --- Confusion matrices (emoji-only) ---\n",
        "\n",
        "    cm_base = confusion_matrix(y_e, b_e)\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    sns.heatmap(cm_base, annot=True, fmt=\"d\", cmap=olive_beige_cmap)\n",
        "    plt.title(f\"Baseline (emoji-only)\\nF1={base_m['f1']:.3f}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.xticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"])\n",
        "    plt.yticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"], rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    cm_var = confusion_matrix(y_e, v_e)\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    sns.heatmap(cm_var, annot=True, fmt=\"d\", cmap=olive_beige_cmap)\n",
        "    plt.title(f\"Variant (emoji-only)\\nF1={var_m['f1']:.3f}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.xticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"])\n",
        "    plt.yticks([0.5, 1.5], [\"Non-Sarcastic\", \"Sarcastic\"], rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # --- Optional: show a few emoji-only golden/reverse inside emoji subset ---\n",
        "    print(\"\\nEmoji-only GOLDEN (True=1, Baseline=0, Variant=1):\")\n",
        "    gold_e = idxs[np.where((y_e == 1) & (b_e == 0) & (v_e == 1))[0]]\n",
        "    if len(gold_e) == 0:\n",
        "        print(\"(none)\")\n",
        "    else:\n",
        "        for i, idx in enumerate(gold_e[:5], start=1):\n",
        "            print(f\"[{i}] {texts[idx]}\")\n",
        "\n",
        "    print(\"\\nEmoji-only REVERSE (True=1, Baseline=1, Variant=0):\")\n",
        "    rev_e = idxs[np.where((y_e == 1) & (b_e == 1) & (v_e == 0))[0]]\n",
        "    if len(rev_e) == 0:\n",
        "        print(\"(none)\")\n",
        "    else:\n",
        "        for i, idx in enumerate(rev_e[:5], start=1):\n",
        "            print(f\"[{i}] {texts[idx]}\")\n"
      ],
      "metadata": {
        "id": "JB35LPoThoVT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}